{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Final Project - Notebook 2\n",
    "### Datasets :\n",
    "   > ### Wine Quality Dataset (White)\n",
    "### Authors:\n",
    "> ### Francisco Cunha, 76759\n",
    "> ### João Amaral, 76460"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook corresponds to the second one where the Task C of the final project, corresponding to the evaluation of the model and validation strategies for the wine dataset were implemented. Here we computed some strategies in order to select the best hyperparameters for the model in question and obtain the final accuracy results for the problem at hand.\n",
    "\n",
    "- [Dataset 2: White wine quality dataset](#Dataset-2-:-White-wine-quality-dataset)\n",
    "    - [Task C: Wine Model Evaluation](#Task-C:-Wine-Model-Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 2 : White wine quality dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Disable warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "\n",
    "dataset_white = pd.read_csv('./white_wine.csv') # numerical: https://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "\n",
    "dataset_white['quality'] = dataset_white['quality'].apply(lambda value: 'bad' if value <= 5 else 'medium'\n",
    "                                                          if value<= 7 else 'good')\n",
    "dataset_white['quality'] = pd.Categorical(dataset_white['quality'],categories=['bad','medium','good'])\n",
    "\n",
    "labels_wine = dataset_white.as_matrix(columns=[dataset_white.columns[-1]]) # Y\n",
    "attributes_wine = dataset_white.as_matrix(columns=dataset_white.columns[0:11]) # X\n",
    "features = list(dataset_white.columns[0:11])\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(attributes_wine)\n",
    "X_white_train_std = sc.transform(attributes_wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task C: Model evaluation\n",
    "\n",
    "\n",
    "In order to determine which one of the trained models and which of its parameters can give us the best results we implemented two different validation techniques. \n",
    "The first one simply being an extension to the holdout validation presented in task B except that now we trained the classifiers for other different partition fractions. However this test isn't very conclusive in the end since the results obtained did not differ much from the original 0.3 partition fraction chosen before and it does not select the best hyperparameters of the model. \n",
    "For the second validation technique a nested cross validation method was implemented using the most basic form of cross-validation, known as __k-fold cross-validation__. It partitions the available data into K disjoint chunks of approximately equal size and in each iteration a training set is formed from a different combination of K − 1 chunks, with the remaining chunk used as the test set used to test the classifier.\n",
    "\n",
    "In the paper \"Nested cross-validation when selecting classifiers is overzealous for most practical applications\" the authors consider two procedures for selecting the best algorithm and tuning its hyperparameters via cross-validation: the first called __nested cross-validation__ and the second that had no standard name, to which they called __flat cross-validation__.\n",
    "\n",
    "__Flat cross-validation__\n",
    "\n",
    "In flat cross-validation the hyperparameters of each model are tuned to minimise a cross-validation based estimate of generalisation performance. The cross-validation performance estimate, evaluated for those optimal hyperparameter values, is then used to select the best model to use in operation. This approach is computationally inexpensive, with the drawback that the selected resulting model does not correspond to the highest performing one.\n",
    "\n",
    "__Nested cross-validation__\n",
    "\n",
    "The nested cross-validation providse a performance estimate used to select the optimal model. It is based on the fact that \n",
    "when we used the test set to both select the values of the parameter and evaluate the model, we risk optimistically biasing our model evaluations. For this reason, if a test set is used to select model parameters, then we need a different test set to get an unbiased evaluation of that selected mode. This is where the \"nested\" part comes into play introducing two cross-validation loops:  first, an inner cross validation used to tune the parameters and select the best model and the second outer cross validation is used to evaluate the model selected by the inner cross validation. The computational expense of nested cross-validation, however, is substantially higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout validation\n",
    "\n",
    "For this first validation procedure the split fractions considered were 0.15, 0.20, 0.25, 0.30 and 0.35. The SVM classifier was tested with C parameter equaling to 1 and for each different kernel type. The MLP classifiers was also considered. No hyperparameter optimization searching is done here however. As mentioned this procedure is not very conclusive simply being another preliminary process to obtain try and get closer to model the best classifier. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best accuracy was : 74.49% using an holdout fraction of 0.2 and algorithm MLP\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 5 different partitions considered to split train and test set\n",
    "fractions = [0.15,0.20,0.25,0.30,0.35]\n",
    "svm_kernel = ['linear','poly','rbf','sigmoid']\n",
    "\n",
    "scores = []\n",
    "\n",
    "for frac in fractions:\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X_white_train_std,labels_wine, test_size = frac)\n",
    "    # SVM\n",
    "    for k in svm_kernel:\n",
    "        svc = SVC(kernel=k, C=1.0)\n",
    "        svc.fit(X_train, Y_train)\n",
    "        predictions = svc.predict(X_test)\n",
    "    score = accuracy_score(Y_test, predictions)\n",
    "    scores.append((score,\"SVM \" + k,frac))\n",
    "    # MLP\n",
    "    mlp = MLPClassifier(activation='tanh', hidden_layer_sizes=(10,5),alpha=0.01, max_iter=5000)\n",
    "    mlp.fit(X_train, Y_train)\n",
    "    predictions = mlp.predict(X_test)\n",
    "    score = accuracy_score(Y_test, predictions)\n",
    "    scores.append((score, \"MLP\", frac))\n",
    "    \n",
    "best = max(scores)\n",
    "\n",
    "print(\"The best accuracy was : {:.2%} using an holdout fraction of {} and algorithm {}\"\\\n",
    "       .format(best[0], best[2], best[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Nested and Nested Cross Validation comparison on the white wine dataset\n",
    "\n",
    "Scores were computed over 30 trials over nested and non-nested cross validation using K-Fold for each loop, with K=4 using the source code supplied by scikit-learn at https://scikitlearn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.htmlfbclid=IwAR2mHh8F1RfvHOPNTYoGxWVI_0K8osQrYmn3UghlW3fFS-bgNO92YoI6nOo\n",
    "\n",
    "The obtained numerical output with the average of the differences between the scores obtained in the  and corresponding plot is presented below:\n",
    "\n",
    "###### Average difference of 0.010574 with std. dev. of 0.005965."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./nested_vs_non_nested.png\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"./nested_vs_non_nested.png\",width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this experiment we can conclude that the score difference is not significative and it even ends up being lower in the nested cross validation. One possible reason for this behavior could be due to the fact that, as the paper authors pointed out, the non-nested approach could be biased toward the score obtained since there is no folding applied to the set used to test the classifier in question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested Cross Validation code\n",
    "\n",
    "Next we present the implement code where the nested cross validation takes place. In a first stage we considered our parameter space for the SVM classifier to be the following:\n",
    "    - Kernel: linear, poly, rbf, sigmoid\n",
    "    - Gamma: 1e-2,1e-3, 1e-4\n",
    "    - C: 1, 10, 100, 1000, 10000\n",
    "However the processing time is was taking to calculate reached over 13 hours without until we killed the process and concluded that this approach wasnt going to be feasible with the available time left before the delivery. As such we decided to use a new approach. From the preliminary results obtained in the task B of notebook 1 we can already see a high distinction in the accuracy between the RBF kernel and the remaining. This one out-performs the rest and we can, in a sort of naive approach, assume that it would be the kernel that would give us the best solution, independent from the remaining parameters. As such we then eliminated these bad performing kernels from the parameter space and tested only for Gamma and C allowing the faster extraction of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'C': 10000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.727 (+/-0.018) for {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.678 (+/-0.013) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.628 (+/-0.014) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.734 (+/-0.016) for {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.719 (+/-0.013) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.678 (+/-0.013) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.739 (+/-0.026) for {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.726 (+/-0.023) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.715 (+/-0.013) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.743 (+/-0.035) for {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.730 (+/-0.016) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.718 (+/-0.021) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.745 (+/-0.023) for {'C': 10000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.734 (+/-0.022) for {'C': 10000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.727 (+/-0.023) for {'C': 10000, 'gamma': 0.0001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "svm_params = [{'kernel': ['rbf'], 'gamma': [1e-2,1e-3,1e-4],'C': [1, 10,100, 1000, 10000]}]\n",
    "\n",
    "# CV inner and outer cycles initialization\n",
    "outer_cv = KFold(n_splits=4, shuffle=True, random_state=None)\n",
    "# k = 5, first iteration : train on first four folds and test the fifth\n",
    "inner_cv = KFold(n_splits=4, shuffle=True, random_state=None)\n",
    "\n",
    "clf = GridSearchCV(estimator=SVC(), param_grid=svm_params, n_jobs=-1, cv=inner_cv) # inner CV cycle\n",
    "clf.fit(X_white_train_std, labels_wine)\n",
    "nested_score = cross_val_score(clf, X=X_white_train_std, y=labels_wine, cv=outer_cv).mean() # outer CV cycle\n",
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "# All results\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References \n",
    "\n",
    "Nested cross-validation when selecting classifiers is overzealous for most practical applications: https://arxiv.org/pdf/1809.09446v1.pdf\n",
    "\n",
    "Nested cross validation: https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html?fbclid=IwAR2mHh8F1RfvHOPNTYoGxWVI_0K8osQrYmn3UghlW3fFS-bgNO92YoI6nOo\n",
    "\n",
    "Parameter estimation using grid search with a nested cross-validation: http://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/auto_examples/grid_search_digits.html\n",
    "\n",
    "GridSearchCV with multiple repetitions: https://stackoverflow.com/a/42230764\n",
    "\n",
    "Hyperparameter Tuning the Random Forest in Python : https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "Nested Cross Validation: https://chrisalbon.com/machine_learning/model_evaluation/nested_cross_validation/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
